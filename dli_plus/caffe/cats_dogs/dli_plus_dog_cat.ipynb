{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLI Plus - Cat and Dog Model\n",
    "\n",
    "DLI 電腦視覺課程中，大家已經學會使用 DIGITS 訓練深度學習的模型，也學會使用 DIGITS 訓練好的 caffemodel 使用 python 選寫程式做推論( inference)，並且能成功辨識貓、狗，本堂課我們會教大家如何適用小型的邊緣運算工具 \"jetson nano\" 進行推論。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DIGITS 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到 DLI 課程三中進入 DIGITS 訓練模型，點選 Models 選擇 classification (下圖)\n",
    "![image.JPG](./jupyter_image/train.JPG)\n",
    "選取 Dogs and Cat Dataset ，因為時間的關係我們選擇只訓練一個 epochs (下圖)\n",
    "![image.JPG](./jupyter_image/train2.JPG)\n",
    "選擇 Alexnet ，命名 Model 名稱後點選 Create (下圖)\n",
    "![image.JPG](./jupyter_image/train.JPG)\n",
    "訓練好模型後我們可以看到 Model 存放的路徑 (下圖)\n",
    "![image.JPG](./jupyter_image/d1.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 下載 DIGITS 模型\n",
    "\n",
    "### 需要以下四個檔案:\n",
    "1. caffemodel: 模型的權重、bias、...等\n",
    "\n",
    "2. deploy.prototxt: 模型的架構\n",
    "\n",
    "3. mean.jpg: DIGITS 為了減少運算量，所以將每張圖片減去平均圖片\n",
    "\n",
    "4. test image: 預測圖片\n",
    "\n",
    "### 2.1 下載 caffeemodel 和 deploy.prototxt\n",
    "\n",
    "部署深度神經網絡模型: GPU 任務 3,進入 jupyter notebook 複製網址，如圖反藍的部分(下圖)。\n",
    "\n",
    "![image.png](./jupyter_image/d2.JPG)\n",
    "\n",
    "開啟新的分頁，將複製的網址貼上，就可以進入到放置檔案的位置 (下圖)\n",
    "![image.png](./jupyter_image/d3.JPG)\n",
    "\n",
    "接著進入 /data/digits 路徑中就能看到 DIGITS 所產生的 dataset 與 caffe model 的資料夾(下圖)。\n",
    "\n",
    "![image.png](./jupyter_image/d4.JPG)\n",
    "\n",
    "進入剛剛訓練好 DIGITS model 的路徑 ，就可以看到資料夾中存放的模型 (下圖)\n",
    "![image.png](./jupyter_image/d5.JPG)\n",
    "\n",
    "複製反藍的網址(下圖)。\n",
    "\n",
    "運用 wget 下載 prototxt、caffemodel 檔案到 Jetson Nano\n",
    "\n",
    "![image.png](./jupyter_image/d6.JPG)\n",
    "\n",
    "範例如下:\n",
    "\n",
    "!wget http://ec2-18-221-64-152.us-east-2.compute.amazonaws.com/gzN6dvnx/tree/data/digits/20180301-185638-e918/snapshot_iter_735.caffemodel\n",
    "\n",
    "!wget http://ec2-18-221-64-152.us-east-2.compute.amazonaws.com/gzN6dvnx/tree/data/digits/20180301-185638-e918/deploy.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**複製工作目錄（上文反藍網址標示部分），並替換以下代碼塊中的 ##FIXME##。完成替換之後，執行此單元 (Shift+Enter) 以將其存儲到變數 <code>MODEL_JOB_URL</code> 中，開始下載 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-20 14:51:03--  http://ec2-18-221-209-237.us-east-2.compute.amazonaws.com/PxAPiyP0/tree/data/digits/20191220-064348-34e5/snapshot_iter_147.caffemodel\n",
      "Resolving ec2-18-221-209-237.us-east-2.compute.amazonaws.com (ec2-18-221-209-237.us-east-2.compute.amazonaws.com)... 18.221.209.237\n",
      "Connecting to ec2-18-221-209-237.us-east-2.compute.amazonaws.com (ec2-18-221-209-237.us-east-2.compute.amazonaws.com)|18.221.209.237|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /PxAPiyP0/files/data/digits/20191220-064348-34e5/snapshot_iter_147.caffemodel [following]\n",
      "--2019-12-20 14:51:03--  http://ec2-18-221-209-237.us-east-2.compute.amazonaws.com/PxAPiyP0/files/data/digits/20191220-064348-34e5/snapshot_iter_147.caffemodel\n",
      "Reusing existing connection to ec2-18-221-209-237.us-east-2.compute.amazonaws.com:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 227507816 (217M) [application/octet-stream]\n",
      "Saving to: ‘snapshot_iter_147.caffemodel’\n",
      "\n",
      "_147.caffemodel      87%[================>   ] 190.18M   240KB/s    eta 75s    "
     ]
    }
   ],
   "source": [
    "MODEL_JOB_URL = '##FIXME##'\n",
    "\n",
    "#download caffemodel\n",
    "!wget $MODEL_JOB_URL/snapshot_iter_147.caffemodel\n",
    "\n",
    "#download deploy.prototxt\n",
    "!wget $MODEL_JOB_URL/deploy.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 下載 Mean Image\n",
    "回到 DIGITS 點選 Datasets 點選 Dogs and Cats (下圖)\n",
    "![image.png](./jupyter_image/mean1.JPG)\n",
    "進入後我們就可以看到存放 Mean Image 資料夾的位置\n",
    "![image.png](./jupyter_image/m2.JPG)\n",
    "至另一個資料夾複製網址，運用 wget 下載 mean image\n",
    "\n",
    "![image.png](./jupyter_image/m3.JPG)\n",
    "\n",
    "範例:\n",
    "\n",
    "!wget http://ec2-3-17-154-139.us-east-2.compute.amazonaws.com/rjV2Gu9T/tree/data/digits/20180222-165843-ada0/mean.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**複製工作目錄（上文反藍網址標示部分），並替換以下代碼塊中的 ##FIXME##。完成替換之後，執行此單元 (Shift+Enter) 以將其存儲到變數 <code>MEAN_IMAGE_URL</code> 中，開始下載平均圖片** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download mean image\n",
    "MEAN_IMAGE_URL = '##FIXME##'  ## Remember to set this to be the job directory for your model\n",
    "!wget $MEAN_IMAGE_URL/mean.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如無法下載模型，將 \"#\" 去除後執行以下指令，把模型移動至當前目錄** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp ./models/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 下載測試圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-03 17:09:42--  https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12234558/Chinook-On-White-03.jpg\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.129.5\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.129.5|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25761 (25K) [image/jpeg]\n",
      "Saving to: ‘Chinook-On-White-03.jpg.1’\n",
      "\n",
      "Chinook-On-White-03 100%[===================>]  25.16K   121KB/s    in 0.2s    \n",
      "\n",
      "2020-03-03 17:09:43 (121 KB/s) - ‘Chinook-On-White-03.jpg.1’ saved [25761/25761]\n",
      "\n",
      "--2020-03-03 17:09:43--  https://www.cats.org.uk/media/2197/financial-assistance.jpg\n",
      "Resolving www.cats.org.uk (www.cats.org.uk)... 104.41.217.88\n",
      "Connecting to www.cats.org.uk (www.cats.org.uk)|104.41.217.88|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 182555 (178K) [image/jpeg]\n",
      "Saving to: ‘financial-assistance.jpg.1’\n",
      "\n",
      "financial-assistanc 100%[===================>] 178.28K  31.1KB/s    in 5.7s    \n",
      "\n",
      "2020-03-03 17:09:51 (31.1 KB/s) - ‘financial-assistance.jpg.1’ saved [182555/182555]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dog image\n",
    "!wget https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12234558/Chinook-On-White-03.jpg\n",
    "#cat image\n",
    "!wget https://www.cats.org.uk/media/2197/financial-assistance.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 開始進行推論\n",
    "準備好檔案後，執行下方程式就可以在 Jetson Nano 上執行貓狗辨識的模型。\n",
    "\n",
    "接下來輸入欲預測的圖片 : financial-assistance.jpg  或是 Chinook-On-White-03.jpg\n",
    "\n",
    "**複製上方圖片名稱，並替換以下代碼塊中的 ##FIXME##。完成替換之後，執行此單元 (Shift+Enter) 以將其存儲到變數 <code>TEST_IMAGE</code> 中** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input test image\n",
    "TEST_IMAGE = '##FIXME##'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果覺得我們訓練的模型不夠好，可以使用 DLI 課程所提供的 caffemodel ，將下方程式碼中的 WEIGHTS 進行更換如下\n",
    "\n",
    "snapshot_iter_147.caffemodel 替換成 snapshot_iter_735.caffemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.04474 sec\n",
      "output label:cat\n"
     ]
    }
   ],
   "source": [
    "import caffe\n",
    "import sys\n",
    "#import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "ARCHITECTURE = './deploy.prototxt'\n",
    "WEIGHTS = './snapshot_iter_735.caffemodel'\n",
    "\n",
    "net = caffe.Classifier(ARCHITECTURE, WEIGHTS,\n",
    "                       channel_swap=(2,1,0),\n",
    "                       raw_scale=255,\n",
    "                       image_dims=(256, 256))\n",
    "\n",
    "\n",
    "input_image= caffe.io.load_image(TEST_IMAGE)\n",
    "test_image = cv2.resize(input_image, (256,256))\n",
    "\n",
    "mean_image = caffe.io.load_image('./mean.jpg')\n",
    "test_image = test_image-mean_image\n",
    "\n",
    "labels = ['cat','dog']\n",
    "\n",
    "start_time = time.time()\n",
    "prediction = net.predict([test_image])\n",
    "total_time = time.time() -start_time\n",
    "print(\"time: {0:.5f} sec\".format(total_time))\n",
    "\n",
    "print('output label:{}'.format(labels[prediction.argmax()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用 RPi 的攝像頭進行即時的辨識 (如是用 USB 攝像頭請跳到 第4個章節)\n",
    "設定鏡頭顯示在螢幕上圖片的大小 (長、寬、高) 和每秒 frame 的數量，這邊設定為display大小: 640 x 360 ; 60 frame/second ; rotate - 180 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gstreamer_pipeline (capture_width=640, capture_height=360, display_width=640, display_height=360, framerate=60, flip_method=2) :\n",
    "    return ('nvarguscamerasrc ! '\n",
    "    'video/x-raw(memory:NVMM), '\n",
    "    'width=(int)%d, height=(int)%d, '\n",
    "    'format=(string)NV12, framerate=(fraction)%d/1 ! '\n",
    "    'nvvidconv flip-method=%d ! '\n",
    "    'video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! '\n",
    "    'videoconvert ! '\n",
    "    'video/x-raw, format=(string)BGR ! appsink'  % (capture_width,capture_height,framerate,flip_method,display_width,display_height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過 openC V模組的 VideoCapture 影片擷取的功能，投過 VideoCapture 連接到攝像頭，再投過 cap.read() 擷取圖像，將擷取的圖片做 normalization 再放到 caffe model 進行辨識，執行後就會應用 Xming 顯示在螢幕上。\n",
    "![image.png](./jupyter_image/cat_dog_05.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gstreamer_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8f9fd9f21fc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] starting video stream...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgstreamer_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_GSTREAMER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamedWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWINDOW_AUTOSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gstreamer_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] starting video stream...\")\n",
    "cap = cv2.VideoCapture(gstreamer_pipeline(), cv2.CAP_GSTREAMER)\n",
    "\n",
    "if cap.isOpened():\n",
    "    cv2.namedWindow('Frame', cv2.WINDOW_AUTOSIZE)   \n",
    "    while cv2.getWindowProperty('Frame', 0) >= 0:\n",
    "        # grab the frame from the threaded video stream\n",
    "        ret, frame = cap.read() \n",
    "        #normalization image\n",
    "        test_image = cv2.resize(frame, (256,256))/255\n",
    "        \n",
    "        #import mean image\n",
    "        mean_image = caffe.io.load_image(DATASET_JOB_DIR + '/mean.jpg')\n",
    "        test_image = test_image-mean_image\n",
    "        \n",
    "        start_time = time.time()\n",
    "        prediction = net.predict([test_image])\n",
    "        total_time = time.time() -start_time\n",
    "\n",
    "        description = 'output label:{} , {:.2f} %'.format(labels[prediction[0].argmax()],prediction[0].max()*100)\n",
    "\n",
    "        cv2.putText(frame, description, (10, 40), cv2.FONT_ITALIC,\n",
    "                0.75, (0, 255, 0), 2)\n",
    "        \n",
    "        #display(frame)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        keyCode = cv2.waitKey(30) & 0xFF\n",
    "        if keyCode == 27:\n",
    "            break\n",
    "\n",
    "        #do a bit of cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 使用 USB 攝像頭進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "from imutils.video import VideoStream\n",
    "labels = ['cat','dog']\n",
    "\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "writer = None\n",
    "time.sleep(2.0)\n",
    "\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream\n",
    "    frame = vs.read()\n",
    "    \n",
    "    # convert the input frame from BGR to RGB then resize it to have\n",
    "    # a width of 750px (to speedup processing)\n",
    "    #rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # rgb = imutils.resize(frame, width=750)\n",
    "    test_image = cv2.resize(frame, (256,256))/255\n",
    "    #test_image = cv2.resize(rgb_small_frame,(256,256))\n",
    "\n",
    "    #img=Image.open('/root/SharDir/20190816-084140-3ab8_epoch_30.0/img/1.jpg')\n",
    "    #test_image = cv2.resize(img, (28,28))\n",
    "    #mean_image = caffe.io.load_image('./mean.jpg')\n",
    "    test_image = test_image-mean_image\n",
    "    start_time = time.time()\n",
    "    prediction = net.predict([test_image])\n",
    "    total_time = time.time() -start_time\n",
    "    #print(\"time: {0:.5f} sec\".format(total_time))\n",
    "    description = 'output label:{} , {} %'.format(labels[prediction.argmax()],prediction[0].max()*100)\n",
    "    description4 = \"predicted time: {0:.5f} sec\".format(total_time)\n",
    "    #print 'output label:', labels[prediction[0].argmax()]\n",
    "    #print(prediction)\n",
    "    cv2.putText(frame, description, (10, 40), cv2.FONT_ITALIC,0.75, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, description4, (440, 450), cv2.FONT_ITALIC,\n",
    "                    0.5, (0, 0, 255), 2)\n",
    "    \n",
    "    #display(frame)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    keyCode = cv2.waitKey(30) & 0xFF\n",
    "    if keyCode == 27:\n",
    "        break\n",
    "\n",
    "    #do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 重新訓練較佳的模型\n",
    "如覺得 Model 準確度不夠，可回到第二章節運用DIGITS重新訓練\n",
    "\n",
    "**複製存放 Model 的網址目錄，並替換以下代碼塊中的 ##FIXME##。完成替換之後，執行此單元 (Shift+Enter) 以將其存儲到變數 <code>MODEL_JOB_URL</code> 中，開始下載 model**\n",
    "\n",
    "**caffemodel 名稱，並替換以下代碼塊中的 ##FIXME##。完成替換之後，執行此單元 (Shift+Enter) 以將其存儲到變數 <code>model_name</code> 中，開始下載 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-05 11:49:44--  http://ec2-18-219-154-112.us-east-2.compute.amazonaws.com/BSylqvUJ/tree/data/digits/20191205-031941-e086/snapshot_iter_2940.caffemodel\n",
      "Resolving ec2-18-219-154-112.us-east-2.compute.amazonaws.com (ec2-18-219-154-112.us-east-2.compute.amazonaws.com)... 18.219.154.112\n",
      "Connecting to ec2-18-219-154-112.us-east-2.compute.amazonaws.com (ec2-18-219-154-112.us-east-2.compute.amazonaws.com)|18.219.154.112|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /BSylqvUJ/files/data/digits/20191205-031941-e086/snapshot_iter_2940.caffemodel [following]\n",
      "--2019-12-05 11:49:45--  http://ec2-18-219-154-112.us-east-2.compute.amazonaws.com/BSylqvUJ/files/data/digits/20191205-031941-e086/snapshot_iter_2940.caffemodel\n",
      "Reusing existing connection to ec2-18-219-154-112.us-east-2.compute.amazonaws.com:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 227507816 (217M) [application/octet-stream]\n",
      "Saving to: ‘snapshot_iter_2940.caffemodel’\n",
      "\n",
      "snapshot_iter_2940. 100%[===================>] 216.97M  1.47MB/s    in 2m 20s  \n",
      "\n",
      "2019-12-05 11:52:05 (1.55 MB/s) - ‘snapshot_iter_2940.caffemodel’ saved [227507816/227507816]\n",
      "\n",
      "--2019-12-05 11:52:05--  http://ec2-18-219-154-112.us-east-2.compute.amazonaws.com/BSylqvUJ/tree/data/digits/20191205-031941-e086/deploy.prototxt\n",
      "Resolving ec2-18-219-154-112.us-east-2.compute.amazonaws.com (ec2-18-219-154-112.us-east-2.compute.amazonaws.com)... 18.219.154.112\n",
      "Connecting to ec2-18-219-154-112.us-east-2.compute.amazonaws.com (ec2-18-219-154-112.us-east-2.compute.amazonaws.com)|18.219.154.112|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /BSylqvUJ/files/data/digits/20191205-031941-e086/deploy.prototxt [following]\n",
      "--2019-12-05 11:52:06--  http://ec2-18-219-154-112.us-east-2.compute.amazonaws.com/BSylqvUJ/files/data/digits/20191205-031941-e086/deploy.prototxt\n",
      "Reusing existing connection to ec2-18-219-154-112.us-east-2.compute.amazonaws.com:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4833 (4.7K) [application/octet-stream]\n",
      "Saving to: ‘deploy.prototxt.1’\n",
      "\n",
      "deploy.prototxt.1   100%[===================>]   4.72K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-12-05 11:52:06 (13.5 MB/s) - ‘deploy.prototxt.1’ saved [4833/4833]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_JOB_URL = '##FIXME##'  ## Remember to set this to be the job directory for your model\n",
    "model_name = '##FIXME##'\n",
    "#download caffemodel\n",
    "!wget $MODEL_JOB_URL/$model_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
